# Capital One - AI Engineer (Intelligent Foundations and Experiences)

## Job Metadata

**Company:** Capital One
**Role:** AI Engineer (IFX Team)
**Location:** Not specified (likely hybrid/remote)
**Team:** Intelligent Foundations and Experiences (IFX)
**Date Posted:** 2025-11-04
**Application Status:** researching
**Fit Score:** 92%

## Job Description

### Overview
Capital One is building responsible and reliable AI systems to transform banking. The IFX team advances state-of-the-art AI engineering and builds proprietary solutions delivering value to millions of customers. AI models and platforms empower teams across Capital One to enhance products with transformative AI power.

### Team: Intelligent Foundations and Experiences (IFX)
- At center of AI vision at Capital One
- Works hand-in-hand with partners across company
- Advances state of the art in science and AI engineering
- Builds and deploys proprietary solutions central to business
- Delivers value to millions of customers
- Empowers teams to enhance products with AI responsibly and at scale

### Responsibilities
- Partner with cross-functional team (engineers, research scientists, TPMs, PMs) to deliver AI-powered products
- Design, develop, test, deploy, and support AI software components:
  - Foundation model training
  - Large language model inference
  - Similarity search
  - Guardrails
  - Model evaluation
  - Experimentation
  - Governance
  - Observability
- Leverage broad stack: AWS Ultraclusters, Huggingface, VectorDBs, Nemo Guardrails, PyTorch
- Invent and introduce state-of-the-art LLM optimization techniques (scalability, cost, latency, throughput)
- Contribute to technical vision and long-term roadmap of foundational AI systems

### Basic Qualifications
- Bachelor's + 3 years AI/ML experience OR Master's + 1 year AI/ML experience
- 3+ years programming with Python, Go, Scala, or Java

### Preferred Qualifications
- 4 years deploying scalable and responsible AI solutions on cloud (AWS, GCP, Azure)
- Experience developing, delivering, and supporting AI services
- Experience with AI/ML algorithms: LLM Inference, Similarity Search, VectorDBs, Guardrails, Memory (Python, C++, C#, Java, Golang)
- Experience with state-of-the-art optimization techniques for training/inference (hardware utilization, latency, throughput, cost)

### The Ideal Candidate
- Loves building systems, takes pride in quality, passionate about doing right thing
- Wants to work on problems that change banking for good
- Stays abreast of latest research, understands scientific publications, applies novel techniques in production
- Adapts quickly, thrives on bringing clarity to big undefined problems
- Loves asking questions, digging deep to find root problems, articulates findings clearly
- Has courage to share new ideas even when unproven
- Deeply technical: strong foundation in engineering/mathematics
- Expertise in hardware, software, AI enables seeing optimization opportunities others miss
- Resilient trailblazer who forges new paths when route is unknown

## Fit Assessment

### Strengths (Perfect Matches)

**Production AI Serving Millions:**
- GridCOP: Production multi-agent system (50-100 daily queries)
- Freefly Tool: 200+ daily users in production
- Track record of systems that serve real customers (exactly what they want)

**Foundation Model Inference:**
- Ollama, Llama 3.2, Claude, OpenAI APIs in production
- Real-time inference optimization
- Cost and latency management

**Similarity Search & VectorDBs:**
- FAISS, Pinecone implementation
- RAG pipelines in production
- Vector search for intelligent querying

**Guardrails & Model Evaluation:**
- Built evaluation frameworks tracking quality metrics
- Model governance practices
- Human-in-the-loop (HIL) validation
- Observability and monitoring systems

**PyTorch & ML Frameworks:**
- PyTorch, TensorFlow, scikit-learn listed
- Classical ML background + modern LLM experience

**AWS Cloud Deployment (4+ years):**
- 2021-2025: AWS production deployments
- CI/CD pipelines, monitoring, cost optimization
- Scalable cloud infrastructure

**Optimization for Cost/Latency/Throughput:**
- 70% efficiency gains through optimization
- Production systems with performance tuning
- Cost monitoring and management

**Cross-functional Leadership:**
- Led cross-functional teams
- Translated business requirements to AI solutions
- Collaborated with stakeholders

**Python Programming (5+ years):**
- Exceeds "3+ years" requirement
- Production Python in AI systems since 2020

**Responsible AI:**
- Human-in-the-loop evaluation
- Guardrails and safety considerations
- Model governance and observability

**Master's in CS + 5 Years AI/ML:**
- Far exceeds "Master's + 1 year" requirement
- 2025 (current) - 2020 = 5+ years AI/ML production work

### Potential Concerns

**Foundation Model Training:**
- Your experience is primarily inference, not training large models at scale
- **Mitigation:** You have strong ML fundamentals (PyTorch, TensorFlow), can learn training quickly
- Emphasize: "Expertise enables seeing optimization opportunities others miss"

**Huggingface/AWS Ultraclusters:**
- Not explicitly mentioned in your resume
- **Mitigation:** Strong AWS experience, open-source framework experience
- These are tools, not fundamental skills

**Go/Scala/Java:**
- You have Python, C++, TypeScript, JavaScript
- No Go, Scala, or Java explicitly listed
- **Mitigation:** "3+ years Python" requirement is met, other languages are nice-to-have
- C++ shows systems programming depth

**Scale: "Millions of customers":**
- Your systems: 50-100 queries (GridCOP), 200+ users (Freefly)
- Not yet "millions" scale
- **Mitigation:** Emphasize scalability design, cloud architecture, performance optimization
- Show ability to design for scale even if current systems are smaller

### Gaps (Minor)

**State-of-the-Art Research Application:**
- You stay current with frameworks (LangGraph, MCP)
- May need to show more depth in reading/applying research papers
- **Mitigation:** Emphasize rapid adoption of cutting-edge techniques, experimentation mindset

## Resume Customization Strategy

### Summary Customization
**Focus:** Production AI systems + LLM inference + optimization + responsible AI + cross-functional leadership

**Key Messages:**
1. "AI Engineer with 5+ years building production AI systems serving real customers at scale"
2. "Deep expertise in LLM inference, similarity search, model evaluation, and guardrails"
3. "Optimization mindset: 70-80% efficiency gains through performance tuning, cost optimization, and scalability design"
4. "Responsible AI practices: evaluation frameworks, observability, governance"
5. "Cross-functional leadership translating business needs to AI solutions"

### Skills Reordering
**Priority order:**
1. AI/ML Frameworks (LLM Inference focus: PyTorch, LangChain, RAG, Model Evaluation, Guardrails, Observability)
2. Programming (Python first, then C++, TypeScript)
3. Cloud & Infrastructure (AWS, CI/CD, Monitoring, Cost Optimization, Scalability)
4. Product & Collaboration (Cross-functional Leadership, Responsible AI)

### Work Experience Highlights
**Grid CoOperator (All 3 bullets):**
- Multi-agent system = complex AI orchestration
- Model evaluation, observability, cost monitoring
- AWS deployment with CI/CD

**Freefly (Customize bullet 1):**
- LLM inference in production (Ollama, Llama 3.2)
- Model evaluation metrics and monitoring
- Serving 200+ daily users

**Keep Lumenier and York:**
- Shows engineering depth and adaptability
- Optimization and performance tuning background

### Projects Selection
1. **GridCOP** - Multi-agent, RAG, vector search (FAISS), evaluation, AWS deployment
2. **Production System Optimization Tool** - LLM inference, 200+ users, real-time processing
3. **AI Travel Planner** - LLM integration, conversational AI

### Keywords to Include
- LLM inference
- Similarity search
- VectorDBs (FAISS, Pinecone)
- Guardrails
- Model evaluation
- Observability
- PyTorch
- AWS
- Optimization (cost, latency, throughput)
- Responsible AI
- Scalability
- Cross-functional collaboration
- Production AI systems
- Foundation models
- Governance

## Application Strategy

### Timeline
- **Today:** Submit application via Capital One careers
- **Day 1-3:** Network with Capital One AI engineers on LinkedIn
- **Day 3-7:** Research IFX team publications/blog posts
- **Week 2:** Follow-up if no response

### Networking Approach
1. Search LinkedIn for "Capital One AI Engineer" or "Capital One IFX"
2. Look for people with "Intelligent Foundations" or "AI Platform" in their titles
3. Connect with 3-5 engineers (personalized requests mentioning shared AI interests)
4. Engage with Capital One Tech blog posts

### Interview Preparation Focus
1. **LLM inference optimization:** Be ready to discuss latency, throughput, cost trade-offs
2. **Similarity search deep dive:** FAISS implementation, chunking strategies, vector DB choices
3. **Model evaluation:** Metrics selection, evaluation frameworks, A/B testing
4. **Guardrails:** Safety considerations, content filtering, responsible AI
5. **AWS architecture:** Scalability design, cost optimization, monitoring
6. **Optimization examples:** Specific techniques you've used to improve performance
7. **Cross-functional collaboration:** How you work with PMs, researchers, stakeholders
8. **Responsible AI:** Your approach to governance, safety, transparency

### Questions to Ask
1. What does the IFX team's AI platform look like? (architecture, scale)
2. How do you balance cutting-edge research with production reliability?
3. What's the biggest AI optimization challenge you're tackling right now?
4. How does the team contribute to Capital One's responsible AI principles?
5. What does success look like in first 6 months for this role?
6. How does IFX collaborate with product teams across Capital One?
7. What's the team's approach to staying current with AI research?

## Why This Role is Compelling

**Strengths:**
- Impact at scale: Millions of customers (vs. hundreds in current role)
- State-of-the-art AI: Foundation models, cutting-edge optimization
- Responsible AI focus: Aligns with your HIL/governance experience
- Cross-functional collaboration: Work with researchers, PMs, engineers
- Technical depth: Inference optimization, hardware/software expertise
- Enterprise resources: AWS Ultraclusters, world-class infrastructure
- Career growth: From startup scale to enterprise scale AI

**Potential Concerns:**
- Large enterprise (vs. startup flexibility)
- May be less autonomy than current role
- Banking domain (vs. energy/robotics domains you know)

**Overall:** This is an exceptional opportunity to work on production AI at massive scale with cutting-edge technology and responsible AI practices. The IFX team is building foundational AI systems that power products for millionsâ€”exactly the kind of high-impact work that matches your experience and aspirations.

## Application Prepared Using

- **Template:** AI Engineer (modified for enterprise/infrastructure role)
- **Time Estimate:** ~15 minutes (using pre-optimized template)
- **Customization:** Summary emphasizing LLM inference, optimization, responsible AI, scale
